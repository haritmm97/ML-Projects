{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_python_script.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNuubdXFbAC9Kk2L4dFLZcz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haritmm97/ML-Projects-Portfolio/blob/master/Capstone_polyreg_python_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzM5vXD5J4oq",
        "colab_type": "code",
        "outputId": "dd928c75-a367-4b0c-c7ae-04913b34ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L932koMDKIey",
        "colab_type": "code",
        "outputId": "a5c0be07-cce5-4556-8612-cbf24966c5ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from IPython.display import Image\n",
        "from graphviz import Source\n",
        "from sklearn import tree\n",
        "import pydotplus\n",
        "\n",
        "dfdata = pd.read_csv(\"/content/drive/My Drive/Machine Learning/Great Learning/Capstone/innercity.csv\")\n",
        "\n",
        "#converting the dayhours to get the year and month on which it was sold\n",
        "dfdata['dayhours']=dfdata['dayhours'].astype('datetime64[ns]')\n",
        "dfdata['soldyr']=pd.DatetimeIndex(dfdata['dayhours']).year\n",
        "dfdata['soldmonth']=pd.DatetimeIndex(dfdata['dayhours']).month\n",
        "\n",
        "#dropping dayhours column\n",
        "house_data=dfdata.drop('dayhours',axis=1)\n",
        "\n",
        "#Removing yr_renovated column\n",
        "house_dat=house_data.drop('yr_renovated',axis=1)\n",
        "#Adding a column to flag the renovation\n",
        "house_dat['renovated']=0\n",
        "house_dat['renovated'].loc[((house_dat['living_measure']<house_dat['living_measure15'])|(house_dat['living_measure']>house_dat['living_measure15'])|(house_dat['lot_measure']<house_dat['lot_measure15'])|(house_dat['lot_measure']>house_dat['lot_measure15']))]=1\n",
        "\n",
        "#Removing living_measure 15 and lot_measure15 columns\n",
        "house_dat1=house_dat.drop(['living_measure15','lot_measure15'],axis=1)\n",
        "\n",
        "#creating new variable \"cost_persqft\" to main df\n",
        "house_dat1['cost_persqft'] = house_dat1['price']/house_dat1['total_area']\n",
        "\n",
        "house_dat1['median_cost_persqft'] = house_dat1.groupby('zipcode')['cost_persqft'].transform(np.median)\n",
        "\n",
        "costpsft_zip = house_dat1[['zipcode', 'median_cost_persqft']]\n",
        "\n",
        "costpsft_zip = costpsft_zip.drop_duplicates(subset='zipcode', keep=\"last\")\n",
        "\n",
        "house_dat1=house_dat1.drop(['cost_persqft', 'median_cost_persqft'],axis=1)\n",
        "\n",
        "house_dat1 = pd.merge(house_dat1, costpsft_zip, on='zipcode')\n",
        "\n",
        "#removing the cid column as it doesnt conribute to price\n",
        "house_dat2=house_dat1.drop(['cid'],axis=1)\n",
        "\n",
        "house_dat2['ceil'] = pd.Categorical(house_dat2.ceil)\n",
        "house_dat2['coast'] = pd.Categorical(house_dat2.coast)\n",
        "house_dat2['sight'] = pd.Categorical(house_dat2.sight)\n",
        "house_dat2['condition'] = pd.Categorical(house_dat2.condition)\n",
        "house_dat2['quality'] = pd.Categorical(house_dat2.quality)\n",
        "house_dat2['furnished'] = pd.Categorical(house_dat2.furnished)\n",
        "house_dat2['renovated'] = pd.Categorical(house_dat2.renovated)\n",
        "house_dat2['zipcode'] = pd.Categorical(house_dat2.zipcode)\n",
        "\n",
        "house_dat2.drop([\"soldyr\", \"soldmonth\", \"lat\", \"long\"], axis = 1, inplace = True)\n",
        "\n",
        "house_dat2['current_yr'] = 2015\n",
        "# creating \"house_age\" feature by subracting yr_built to 2015\n",
        "house_dat2['house_old'] = house_dat2['current_yr'] - house_dat2['yr_built']\n",
        "house_dat2.drop([\"current_yr\", \"yr_built\"], axis = 1, inplace = True)\n",
        "house_dat2.head()\n",
        "\n",
        "df_zip = pd.read_csv(\"/content/drive/My Drive/Machine Learning/Great Learning/Capstone/zipcode3.csv\")\n",
        "df_zip.drop([\"region\", \"link1\", \"link2\"], axis = 1, inplace = True)\n",
        "\n",
        "df_zip[\"Total_population\"] = df_zip[\"Total_population\"].str.replace(\",\",\"\").astype(float)\n",
        "df_zip[\"Housing_units\"] = df_zip[\"Housing_units\"].str.replace(\",\",\"\").astype(float)\n",
        "df_zip[\"Density\"] = df_zip[\"Density\"].str.replace(\",\",\"\").astype(float)\n",
        "df_zip[\"White_Population\"] = df_zip[\"White_Population\"].str.replace(\",\",\"\").astype(float)\n",
        "df_zip[\"Median_Income\"] = df_zip[\"Median_Income\"].str.replace(\",\",\"\").astype(float)\n",
        "\n",
        "df_zip['white_perc'] = df_zip['White_Population']/df_zip['Total_population']\n",
        "df_zip['per_capita_house'] = df_zip['Housing_units']/df_zip['Total_population']\n",
        "\n",
        "house_dat2 = pd.merge(house_dat2, df_zip, on='zipcode')\n",
        "\n",
        "house_dat2.drop([\"Total_population\", \"Housing_units\", \"White_Population\"], axis = 1, inplace = True)\n",
        "\n",
        "house_dat2['zipcode'] = pd.Categorical(house_dat2.zipcode)\n",
        "\n",
        "# Fetch all numeric features\n",
        "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "numeric = []\n",
        "for i in house_dat2.columns:\n",
        "    if house_dat2[i].dtype in numeric_dtypes:\n",
        "        numeric.append(i)\n",
        "\n",
        "from scipy.stats import zscore\n",
        "house_dat2[numeric] = house_dat2[numeric].apply(zscore)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X=house_dat2.drop('price',axis=1) #Indepedent feature columns\n",
        "y=house_dat2['price'] # dependent feature column\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "polymodel = PolynomialFeatures(degree=2,interaction_only=True)\n",
        "poly_x_train = polymodel.fit_transform(x_train)\n",
        "poly_x_test = polymodel.fit_transform(x_test)\n",
        "linear_polymodel = linear_model.LinearRegression()\n",
        "linear_polymodel.fit(poly_x_train,y_train)\n",
        "#predict using test\n",
        "poly_y_predict=linear_polymodel.predict(poly_x_test)\n",
        "#predict using training data\n",
        "poly_y_predict_trn=linear_polymodel.predict(poly_x_train)\n",
        "\n",
        "#polynomial regression model score\n",
        "model_score_polytrn=linear_polymodel.score(poly_x_train,y_train)\n",
        "print(\"Polynomial regresion model score using training data:\",model_score_polytrn)\n",
        "model_score_poly=linear_polymodel.score(poly_x_test,y_test)\n",
        "print(\"Polynomial regresion model score using test data:\",model_score_poly)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Polynomial regresion model score using training data: 0.8809290330108911\n",
            "Polynomial regresion model score using test data: 0.8718794021889589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IV4YgYb1X11e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}